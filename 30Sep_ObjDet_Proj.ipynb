{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EE4309 Object Detectation Project - Google Colab Version\n",
    "\n",
    "This notebook maintains the same experience as the local Makefile commands, allowing you to easily run the project on Colab.\n",
    "\n",
    "## üìù Important Notes\n",
    "1. **Enable GPU**: Click `Runtime` ‚Üí `Change runtime type` ‚Üí Select `T4 GPU`\n",
    "2. **Run Order**: Please run cells in sequence\n",
    "3. **Command Mapping**: Each cell corresponds to a make command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Step 0: Clone Project and Enter Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\Desktop\\NUS\\Y4S1\\EE4309\\Labs\\EE4309_proj\n",
      "c:\\Users\\Admin\\Desktop\\NUS\\Y4S1\\EE4309\\Labs\\EE4309_proj\n"
     ]
    }
   ],
   "source": [
    "# !git clone https://github.com/Enderfga/EE4309_proj.git\n",
    "%cd EE4309_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Setup (equivalent to `make setup`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install project dependencies (equivalent to make setup)\n",
    "!pip install -q -r requirements.txt -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PyTorch version: 2.8.0+cpu\n",
      "‚úÖ CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "# Verify environment\n",
    "import torch\n",
    "print(f\"‚úÖ PyTorch version: {torch.__version__}\")\n",
    "print(f\"‚úÖ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"‚úÖ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Help (equivalent to `make help`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/bash: Files\\Git\\bin\\bash.exe: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Show all available commands (equivalent to make help)\n",
    "!make help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üñºÔ∏è Step 2: Download Samples (equivalent to `make samples`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download sample images (equivalent to make samples)\n",
    "!make samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Step 3: Train Model (equivalent to `make train`)\n",
    "\n",
    "**Note**: On Colab, consider using fewer epochs to save time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifications made to training\n",
    "\n",
    "1. Add ColourJitter to training transforms\n",
    "2. Change optimiser to AdamW and scheduler to CosineAnnealingLR\n",
    "3. Implement gradient accumulation\n",
    "4. Train with larger batch size (we run into CUDA memory limits using any higher batch sizes)\n",
    "5. Plot training and validation losses across epochs\n",
    "6. t-SNE dimensionality reduction visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard training (equivalent to make train)\n",
    "# model choices: \"reset50\", \"vit\"\n",
    "!make train BATCH_SIZE=1 EPOCHS=2 MODEL=\"vit\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 4: Evaluate Model (equivalent to `make eval`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model (equivalent to make eval)\n",
    "!make eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Step 5: Run Inference (equivalent to `make infer`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference (equivalent to make infer)\n",
    "!make infer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Submit Your Work (equivalent to `make submit`)\n",
    "\n",
    "**Important**: This will create a git commit with your student information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit your work with student information (equivalent to make submit)\n",
    "# You will be prompted to enter:\n",
    "# - Your full name\n",
    "# - Your student ID (format: A0123456X)\n",
    "# - Optional additional message\n",
    "# Please run this command before compressing and submitting your project.\n",
    "!make submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üíæ Extra: Save to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive to save training results\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create save directory\n",
    "!mkdir -p /content/drive/MyDrive/EE4309_results\n",
    "\n",
    "# Copy training results\n",
    "!cp -r runs/* /content/drive/MyDrive/EE4309_results/\n",
    "print(\"‚úÖ Results saved to Google Drive!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Visualize Inference Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "\n",
    "# Detection result images to display\n",
    "detection_images = [\n",
    "    'runs/infer_vis/dog_det.jpg',\n",
    "    'runs/infer_vis/eagle_det.jpg', \n",
    "    'runs/infer_vis/horses_det.jpg',\n",
    "    'runs/infer_vis/person_det.jpg'\n",
    "]\n",
    "\n",
    "# Check which images exist\n",
    "existing_images = [img for img in detection_images if os.path.exists(img)]\n",
    "\n",
    "if len(existing_images) >= 4:\n",
    "    print(\"Displaying inference detection results:\")\n",
    "    \n",
    "    # Create 2x2 grid\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Object Detection Results', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Flatten axes for easy iteration\n",
    "    axes_flat = axes.flatten()\n",
    "    \n",
    "    for i, img_path in enumerate(existing_images[:4]):\n",
    "        try:\n",
    "            img = mpimg.imread(img_path)\n",
    "            axes_flat[i].imshow(img)\n",
    "            # Extract image name without extension for title\n",
    "            img_name = os.path.basename(img_path).replace('_det.jpg', '')\n",
    "            axes_flat[i].set_title(img_name.title(), fontsize=14)\n",
    "            axes_flat[i].axis('off')\n",
    "        except Exception as e:\n",
    "            axes_flat[i].text(0.5, 0.5, f'Error loading\\n{os.path.basename(img_path)}', \n",
    "                            ha='center', va='center', transform=axes_flat[i].transAxes)\n",
    "            axes_flat[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "elif len(existing_images) > 0:\n",
    "    print(f\"Found {len(existing_images)} detection results:\")\n",
    "    \n",
    "    # Calculate grid size for available images\n",
    "    n_images = len(existing_images)\n",
    "    n_cols = min(2, n_images)\n",
    "    n_rows = (n_images + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(8*n_cols, 6*n_rows))\n",
    "    fig.suptitle('Available Detection Results', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Handle single image case\n",
    "    if n_images == 1:\n",
    "        axes = [axes]\n",
    "    elif n_rows == 1:\n",
    "        axes = axes if hasattr(axes, '__iter__') else [axes]\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "    \n",
    "    for i, img_path in enumerate(existing_images):\n",
    "        try:\n",
    "            img = mpimg.imread(img_path)\n",
    "            axes[i].imshow(img)\n",
    "            img_name = os.path.basename(img_path).replace('_det.jpg', '')\n",
    "            axes[i].set_title(img_name.title(), fontsize=14)\n",
    "            axes[i].axis('off')\n",
    "        except Exception as e:\n",
    "            axes[i].text(0.5, 0.5, f'Error loading\\n{os.path.basename(img_path)}', \n",
    "                        ha='center', va='center', transform=axes[i].transAxes)\n",
    "            axes[i].axis('off')\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for i in range(n_images, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No detection result images found.\")\n",
    "    print(\"Please run inference first:\")\n",
    "    print(\"!make infer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Check Git History (View Submission Records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View git commit history to check submissions\n",
    "!git log --oneline -n 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View detailed changes in the last commit\n",
    "!git diff HEAD~1 --stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è Troubleshooting\n",
    "\n",
    "### 1. GPU Out of Memory\n",
    "```bash\n",
    "# Reduce batch size\n",
    "!bash scripts/train.sh --batch-size 64 --epochs 20\n",
    "```\n",
    "\n",
    "### 2. Runtime Limits\n",
    "- Colab free tier has ~12 hour limit\n",
    "- Use checkpoint feature to train in segments\n",
    "- Save to Google Drive regularly\n",
    "\n",
    "### 3. Disconnection Issues\n",
    "- Use resume training feature above to continue\n",
    "- Consider Colab Pro for longer runtime\n",
    "\n",
    "### 4. Submission Issues\n",
    "- Make sure you run `make submit` before the deadline\n",
    "- Use `git log` to verify your submission was recorded\n",
    "- Your instructor can use `git diff` to review your changes"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
